# The Idiosyncratic Effects of Adversarial Training on Bias in Personalized Recommendation Learning

This file presents the reproducibility details of the paper. **The Idiosyncratic Effects of Adversarial Training on Bias in Personalized Recommendation Learning** published at RecSys 2021 LBR Track.

**Table of Contents:**
- [Requirements](#requirements)
- [Datasets](#datasets)
- [Reproducibility Details](#reproducibility-details)
  - [Training of the BPR-MF](#1-training-of-the-bpr-mf)
  - [Training of the APR-MF](#2-recommendations-generation)
  - [Performance Evaluation](#3-performance-evaluation)
  - [Statistical Test](#4-statistical-test)
- [Reproduce the Wine-Glass Phenomenon](#reproduce-the-wine-glass-phenomenon)
- [Simulate Adversarial Perturbation](#simulate-adversarial-perturbation)
- [Full Results](#full-results)
- [Contact](#contact)

## Requirements

To run the experiments, it is necessary to install the following requirements. 

* Python 3.6.9
* CUDA 10.1
* cuDNN 7.6.4

After having clone this repository with 
```
git clone repo-name
```
we suggest creating e virtual environment install the required Python dependencies with the following commands
```
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
## Datasets
The tested datasets across the paper experiments are reported in the following table.

|       Dataset      |   # Users   | # Products   |  # Feedback   | Density | p(i,I<sub>SH</sub>) | p(i,I<sub>LT</sub>) |
| ------------------ |:-----------:| ------------| ------------- | --------| --------------------- | --------------------- | 
|     ML100K     |    934        | 1,682        |  99,999       | 0.0630 | 0.6452                | 0.3548                |
|     Last.fm    |    1,892      | 17,632       |  92,834       | 0.0028 | 0.7893                | 0.2107                |
|     Amazon     |    3,915      | 2,549        |  77,328       | 0.0077 | 0.5747                | 0.4253                |
|     ML1M       |    6,040      | 3,706        |  1,000,209    | 0.0447 | 0.6512                | 0.3488                |
|     Yelp       |    25,677     | 25,815       |  731,671      | 0.0011 | 0.6544                | 0.3456                |

The training and test datasets are available at ```./data/<dataset_name>/``` with the format
```
user-Id [TAB] item-Id [TAB] score [TAB] timestamp
```
 All the experiments are reproducible on any other dataset split following the ```leave-one-out``` protocol and naming the files as ```trainingset.tsc``` and ```testset.tsv```.

## Reproducibility Details

### 1. Training of the BPR-MF
The first step is to train the baseline recommender model with BPR
```
python train_rec.py \
  --gpu -1 \
  --dataset <data-name> \
  --rec bprmf \
  --epochs T-APR \
  --restore_epochs 0 \
  --embed_size <emb-k>\
  --lr <learning-rate> \
  --reg <regularization-term> \
  --k <top-k> \
  --verbose <epoch-to-store-results> 
```
Changing the hyper-parameters following the details presented in the paper it is possible to generate all the initial BPR-F models.
The script will print the performance on ```k```-length recommendation lists. Comparing the performance it is possible to identify the hyper-parameters combination of the best (most accurate) BPR model. Note that we train the BPR model for T<sub>APR</sub> epochs to be fair in comparing BPR with AMR.

### 2. Training of APR-MF
After having selected the best model based on ```lr, reg, embK```, we can start the training by varying teh adversarial regularization coefficient ```alpha``` and the perturbation budget ```epsilon```.
```
python train_rec.py \
  --gpu -1 \
  --dataset <data-name> \
  --rec amf \
  --epochs T-APR \
  --restore_epochs T-BPR \
  --embed_size <emb-k>\
  --lr <learning-rate> \
  --reg <regularization-term> \
  --k <top-k> \
  --list_adv_eps 0.01 0.1 1.0 10 \
  --list_adv_reg 0.001 0.01 0.1 1 10 \
  --verbose <epoch-to-store-results> 
```
At the end of the training of these models, we can select the best APR-MF.

### 3. Performance Evaluation
To measure all the results that we repor tin tha paper, we can execute the following command
```
python evaluate_bias.py \
  --datasets <dataset_name> \
  --list_k 10 50 100
```
At the end of this command, the following file will be created with all the measured metrics on all the list of recommendations generated by the previous training. 

The file is ```.\rec_bias\<dataset_name>\rec_bias.csv```.

### 4. Statistical Test
After having selected the best BPR-MF and APR-MF models, we can compute the statistical significance test by executing the following command
```
python t-test_evaluate_bias.py \
 --datasets <dataste_name> \
 --file_a <bpr-rec-list-name> \
 --files_b <apr-rec-list-name
```

This script will store the statistical test results in ```.\rec_bias\<dataset_name>\ttest_bias_reuslts.csv```.

## Reproduce the Wine-Glass Phenomenon
To reproduce the ***Wine-Glass Phenomenon*** described in the paper its is necessary to execute the following script that automatically produces the figure shown in the paper.
```
python build_gradient_magnitude_plots.py \
 --dataset <dataset_name> \
 --rec amf \
 --epochs T-APR \
 --adv_eps <eps-of-the-best-model> \
 --adv_reg <alpha-of-the-best-model> \
 --gpu -1 
```
At the end of the training the plots will be stored as ```png``` files in the following directory ```.\rec_result\<dataset_name>\build_>model_name>\```.

## Simulate Adversarial Perturbation
We have also implemented the code to simulat ethe adversarial perturbation of a trained model. 
```
python run_attack.py \
  --list_adv_attack_eps 0.001 0.01 
```
where we have to pass all the model parameters on which we want to test the adversarial perturbation, e.g., the one defined in the previous steps, and the list of perturbation magnitude to explore.

The log file will present the performance variations following the method of [Adversarial Personalized Ranking for Recommendation](https://arxiv.org/pdf/1808.03908.pdf) by He et al.

##Full Results

We have published all the recommendation results collected on the grid search training in the ```.\rec_bias``` directory for each tested dataset.

## Authors
* Vito Walter Anelli (vitowalter.anelli@poliba.it)
* Tommaso Di Noia (tommaso.dinoia@poliba.it)
* Felice Antonio Merra<sup id="a1">[*](#f1)</sup> (felice.merra@poliba.it)

<b id="f1"><sup>*</sup></b> Corresponding author

